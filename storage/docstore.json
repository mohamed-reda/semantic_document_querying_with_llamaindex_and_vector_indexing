{"docstore/metadata": {"5df792c2-0d94-4819-9563-5fd313a519cd": {"doc_hash": "6f211b7395a5b80efe1203e33b60d3b8aab562d0dc94c95b3616956a75e95063"}, "67d354a0-8e58-4a6a-b40e-4880c326aa6d": {"doc_hash": "c4f9563fe4f00553c2a6e8ca8bc25fe17a609ecb327b097e4f75a890d6bf3ec4"}, "ff707a45-567f-44ce-89b3-f744c1b9d8bd": {"doc_hash": "6c9c7d2007699ed9f1ed9d60063c1dc9c6bbfe567d63ab62d2bd4acf564ba415"}, "69cb95a0-38a7-44d7-a7a3-8fc1fe855b91": {"doc_hash": "0e100f3b6744c4c944e410bf26e08e960663df885e5056aaaede333cfff51190"}, "31ff66e8-bfbc-449e-ae56-756830d52186": {"doc_hash": "2713770aa2d51f0f40e1d35b9c86db37470213d2653a7681897f366a72aeb372"}, "506e44fe-9490-4d7e-9f7c-8e1ff1acc51d": {"doc_hash": "cdba90f110bbf08af3043d07cf80d6fd832235797d080b17fadfd5ff7a21f466"}, "a0ff572f-46cd-4d99-896a-1d3c8f72853d": {"doc_hash": "6b3c7d8026e68098dc8fff5de312a611156be7eab518aab800dc4b3a72e86692"}, "146d9731-e382-429b-961d-c4f8837ee599": {"doc_hash": "0ca87cca19e95307a9d8a9ba62df6943872305664e4ea1d891f5d9073b8917e4"}, "e00004c9-657e-454c-94a7-638ec8065954": {"doc_hash": "6f211b7395a5b80efe1203e33b60d3b8aab562d0dc94c95b3616956a75e95063", "ref_doc_id": "5df792c2-0d94-4819-9563-5fd313a519cd"}, "7af7addd-7c5e-4e45-8f82-b27521921072": {"doc_hash": "c4f9563fe4f00553c2a6e8ca8bc25fe17a609ecb327b097e4f75a890d6bf3ec4", "ref_doc_id": "67d354a0-8e58-4a6a-b40e-4880c326aa6d"}, "97cf30dd-f3d5-4eea-8c7c-2966a304fad4": {"doc_hash": "6c9c7d2007699ed9f1ed9d60063c1dc9c6bbfe567d63ab62d2bd4acf564ba415", "ref_doc_id": "ff707a45-567f-44ce-89b3-f744c1b9d8bd"}, "8a747947-138b-4f6a-88cd-757f4f68e659": {"doc_hash": "0e100f3b6744c4c944e410bf26e08e960663df885e5056aaaede333cfff51190", "ref_doc_id": "69cb95a0-38a7-44d7-a7a3-8fc1fe855b91"}, "9eac1dca-6307-4aa9-9a94-27a83e17eb54": {"doc_hash": "2713770aa2d51f0f40e1d35b9c86db37470213d2653a7681897f366a72aeb372", "ref_doc_id": "31ff66e8-bfbc-449e-ae56-756830d52186"}, "753c0035-3d85-4b5f-a61c-3392b94a6c3c": {"doc_hash": "cdba90f110bbf08af3043d07cf80d6fd832235797d080b17fadfd5ff7a21f466", "ref_doc_id": "506e44fe-9490-4d7e-9f7c-8e1ff1acc51d"}, "7f043c9c-995c-4387-bee6-56a800aca5e9": {"doc_hash": "6b3c7d8026e68098dc8fff5de312a611156be7eab518aab800dc4b3a72e86692", "ref_doc_id": "a0ff572f-46cd-4d99-896a-1d3c8f72853d"}, "52f0739a-b56f-4f3d-8384-60969b532f5a": {"doc_hash": "0ca87cca19e95307a9d8a9ba62df6943872305664e4ea1d891f5d9073b8917e4", "ref_doc_id": "146d9731-e382-429b-961d-c4f8837ee599"}}, "docstore/data": {"e00004c9-657e-454c-94a7-638ec8065954": {"__data__": {"id_": "e00004c9-657e-454c-94a7-638ec8065954", "embedding": null, "metadata": {"file_path": "/Users/tylerreed/_ai-projects/llamaindex-beginner-course/pdf/ag-studio.pdf", "file_name": "ag-studio.pdf", "file_type": "application/pdf", "file_size": 3112466, "creation_date": "2024-09-11", "last_modified_date": "2024-09-10"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "5df792c2-0d94-4819-9563-5fd313a519cd", "node_type": "4", "metadata": {"file_path": "/Users/tylerreed/_ai-projects/llamaindex-beginner-course/pdf/ag-studio.pdf", "file_name": "ag-studio.pdf", "file_type": "application/pdf", "file_size": 3112466, "creation_date": "2024-09-11", "last_modified_date": "2024-09-10"}, "hash": "6f211b7395a5b80efe1203e33b60d3b8aab562d0dc94c95b3616956a75e95063", "class_name": "RelatedNodeInfo"}}, "text": "# AUTOGEN STUDIO: A No-Code Developer Tool for Building and Debugging Multi-Agent Systems\n\n# Victor Dibia, Jingya Chen, Gagan Bansal, Suff Syed, Adam Fourney, Erkang Zhu, Chi Wang, Saleema Amershi\n\n# Microsoft Research, Redmond, United States\n\n{victordibia, jingyachen, gaganbansal, suffsyed, adam.fourney, erkang.zhu, chiw, samershi}@microsoft.com\n\n# Abstract\n\nMulti-agent systems, where multiple agents (generative AI models + tools) collaborate, are emerging as an effective pattern for solving long-running, complex tasks in numerous domains. However, specifying their parameters (such as models, tools, and orchestration mechanisms etc.,) and debugging them remains challenging for most developers. To address this challenge, we present AUTOGEN STUDIO, a no-code developer tool for rapidly prototyping, debugging, and evaluating multi-agent workflows built upon the AUTOGEN framework. AUTOGEN STUDIO offers a web interface and a Python API for representing LLM-enabled agents using a declarative (JSON-based) specification. It provides an intuitive drag-and-drop UI for agent workflow specification, interactive evaluation and debugging of workflows, and a gallery of reusable agent components. We highlight four design principles for no-code multi-agent developer tools and contribute an open-source implementation.1\n\n# 1 Introduction\n\nWhen combined with the ability to act (e.g., using tools), Generative AI models function as agents, enabling complex problem-solving capabilities. Importantly, recent research has shown that transitioning from prescribed (fixed) agent pipelines to a multi-agent setup with autonomous capabilities can result in desirable behaviors such as improved factuality and reasoning (Du et al., 2023), as well as divergent thinking (Liang et al., 2023). These observations have driven the development of application frameworks such as AutoGen (Wu et al., 2023), CAMEL (Li et al., 2024), and TaskWeaver (Qiao et al., 2023), which simplify the process of crafting multi-agent applications expressed as Python code. However, while multi-agent applications advance our capacity to solve complex problems, they also introduce new challenges. For example, developers must now configure a large number of parameters for these systems including defining agents (e.g., the model to use, prompts, tools or skills available to the agent, number of action steps an agent can take, task termination conditions etc.), communication and orchestration mechanisms - i.e., the order or sequence in which agents act as they collaborate on a task. Additionally, developers need to debug and make sense of complex agent interactions to extract signals for system improvement. All of these factors can create significant barriers to entry and make the multi-agent design process tedious and error-prone. To address these challenges, we have developed AUTOGEN STUDIO, a tool for rapidly prototyping, debugging, and evaluating MULTI-AGENT workflows. Our contributions are highlighted as follows:\n\n- AUTOGEN STUDIO - a developer-focused tool (UI and backend Web and Python API) for declaratively specifying and debugging (human-in-the-loop and non-interactive) MULTI-AGENT workflows. AUTOGEN STUDIO provides a novel\n\n# Figure 1\n\nAUTOGEN STUDIO provides a drag-n-drop UI where models, skills/tools, memory components can be defined, attached to agents and agents attached to workflows.\n\n|Agent A|Agent B|\n|---|---|\n|Initiator|Book generation group chat manager|\n|Represent user, execute co..Userproxy|Plan and generate book content including text and images.|\n|Code executor|Content Agent|\n|GPT 4 Turbo|Image Agent|\n|Web search|Generate content for each...|\n|Drag & drop to add a skill|Generate images|\n|QA Agent|Verify the content meet par...|\n|Drag to add a model|Drag to add a skill|\n\n1 https://github.com/microsoft/autogen/tree/autogenstudio/samples/apps/autogen-studio", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3879, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "7af7addd-7c5e-4e45-8f82-b27521921072": {"__data__": {"id_": "7af7addd-7c5e-4e45-8f82-b27521921072", "embedding": null, "metadata": {"file_path": "/Users/tylerreed/_ai-projects/llamaindex-beginner-course/pdf/ag-studio.pdf", "file_name": "ag-studio.pdf", "file_type": "application/pdf", "file_size": 3112466, "creation_date": "2024-09-11", "last_modified_date": "2024-09-10"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "67d354a0-8e58-4a6a-b40e-4880c326aa6d", "node_type": "4", "metadata": {"file_path": "/Users/tylerreed/_ai-projects/llamaindex-beginner-course/pdf/ag-studio.pdf", "file_name": "ag-studio.pdf", "file_type": "application/pdf", "file_size": 3112466, "creation_date": "2024-09-11", "last_modified_date": "2024-09-10"}, "hash": "c4f9563fe4f00553c2a6e8ca8bc25fe17a609ecb327b097e4f75a890d6bf3ec4", "class_name": "RelatedNodeInfo"}}, "text": "# AUTOGEN STUDIO: A No-Code Interface for Multi-Agent Development\n\nWe introduce a drag-and-drop experience (Figure 1) for rapidly authoring complex MULTI-AGENT workflows, tools for profiling/debugging agent sessions, and a gallery of reusable/shareable MULTI-AGENT components.\n\n- We introduce profiling capabilities with visualizations of messages/actions by agents and metrics (costs, tool invocations, and tool output status) for debugging MULTI-AGENT workflows.\n- Based on our experience building and supporting AUTOGEN STUDIO as an open-source tool with a significant user base (over 200K downloads within a 5-month period), we outline emerging design patterns for MULTI-AGENT developer tooling and future research directions.\n- To the best of our knowledge, AUTOGEN STUDIO is the first open-source project to explore a no-code interface for autonomous MULTI-AGENT application development, providing a suitable platform for research and practice in MULTI-AGENT developer tooling.\n\n# 2 Related Work\n\n# 2.1 Agents (LLMs + Tools)\n\nGenerative AI models face limitations, including hallucination \u2014 generating content not grounded in fact \u2014 and limited performance on reasoning tasks or novel out-of-distribution problems. To address these issues, practice has shifted towards agentic implementations where models are given access to tools to act and augment their performance (Mialon et al., 2023). Agentic implementations, such as React (Yao et al., 2022), explore a Reason and Act paradigm that uses LLMs to generate both reasoning traces and task-specific actions in an interleaved manner. As part of this process, developers have explored frameworks that build prescriptive pipelines interleaving models and tools (e.g., LIDA (Dibia, 2023), LangChain (Chase, 2022)). However, as tasks become more complex, requiring lengthy context and the ability to independently adapt to dynamic problem spaces, predefined pipelines demonstrate limited performance (Liu et al., 2024). This limitation has led to the exploration of more flexible and adaptive agent architectures.\n\n# 2.2 MULTI-AGENT Frameworks\n\nSeveral frameworks have been proposed to provide abstractions for creating such applications. AutoGen (Wu et al., 2023) is an open-source extensible framework that allows developers to build large MULTI-AGENT applications. CAMEL (Li et al., 2024) is designed to facilitate autonomous cooperation among communicative agents through role-playing, using inception prompting to guide chat agents toward task completion while aligning with human intentions. OS-Copilot (Wu et al., 2024) introduces a framework for building generalist agents capable of interfacing with comprehensive elements in an operating system, including the web, code terminals, files, multimedia, and various third-party applications. It explores the use of a dedicated planner module, a configurator, and an executor, as well as the concept of tools (Python functions or calls to API endpoints) or skills (tools that can be learned and reused on the fly).\n\n# Multi-Agent Core Concepts\n\n1. Model: Generative AI model used to drive core agent behaviors.\n2. Skills/Tools: Code or APIs used to address specific tasks.\n3. Memory: Short term (e.g., lists) or long term (vector databases) used for to save and recall information.\n4. Agent: A configuration that ties together the model, skills, memory components and behaviors.\n5. Workflow: A configuration of a set of agents and how they interact to address tasks (e.g., order or sequence in which agents act, task planning, termination conditions etc.).\n\nCollectively, these tools support a set of core capabilities - definition of agent parameters - such as generative AI models, skills/tools or memory, and agent workflows - specifications of how these agents can collaborate. However, most of these frameworks primarily support a code-first representation of agent workflows, which presents a high barrier to entry and rapid prototyping. They also do not provide tools or metrics for agent debugging and evaluation. Additionally, they lack structured reusable templates to bootstrap or accelerate the agent workflow creation process. AUTOGEN STU-", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4161, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "97cf30dd-f3d5-4eea-8c7c-2966a304fad4": {"__data__": {"id_": "97cf30dd-f3d5-4eea-8c7c-2966a304fad4", "embedding": null, "metadata": {"file_path": "/Users/tylerreed/_ai-projects/llamaindex-beginner-course/pdf/ag-studio.pdf", "file_name": "ag-studio.pdf", "file_type": "application/pdf", "file_size": 3112466, "creation_date": "2024-09-11", "last_modified_date": "2024-09-10"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "ff707a45-567f-44ce-89b3-f744c1b9d8bd", "node_type": "4", "metadata": {"file_path": "/Users/tylerreed/_ai-projects/llamaindex-beginner-course/pdf/ag-studio.pdf", "file_name": "ag-studio.pdf", "file_type": "application/pdf", "file_size": 3112466, "creation_date": "2024-09-11", "last_modified_date": "2024-09-10"}, "hash": "6c9c7d2007699ed9f1ed9d60063c1dc9c6bbfe567d63ab62d2bd4acf564ba415", "class_name": "RelatedNodeInfo"}}, "text": "# 3 Design Goals\n\nAUTOGEN STUDIO is designed to enhance the MULTI-AGENT developer experience by focusing on three core objectives:\n\n- Rapid Prototyping: Provide a playground where developers can quickly specify agent configurations and compose these agents into effective multi-agent workflows.\n- Developer Tooling: Offer tools designed to help developers understand and debug agent behaviors, facilitating the improvement of multi-agent systems.\n- Reusable Templates: Present a gallery of reusable, shareable templates to bootstrap agent workflow creation. This approach aims to establish shared standards and best practices for MULTI-AGENT system development, promoting wider adoption and implementation of MULTI-AGENT solutions.\n\n# 4 System Design\n\nAUTOGEN STUDIO is implemented across two high-level components: a frontend user interface (UI) and a backend API (web, python and command line). It can be installed via the PyPI package manager (listing 1).\n\npip install autogenstudio\nautogenstudio ui -- port 8081\n\nlisting 1: AUTOGEN STUDIO can be installed from PyPI (pip) and the UI launched from the command line.\n\n# 4.1 User Interface\n\nThe frontend web interface in AUTOGEN STUDIO is built using React and implements three main views that support several key functionalities. The build view enables users to author (define-and-compose) multi-agent workflows. The playground view allows for interactive task execution and workflow debugging, with options to export and deploy. The gallery view facilitates the reuse and sharing of agent artifact templates.\n\n# 4.1.1 Building Workflows\n\nThe build view in the UI (see Figure 1) offers a define-and-compose experience, allowing developers to declaratively define low-level components and iteratively compose them into a workflow. For instance, users can define configurations for models, skills/tools (represented as Python functions addressing specific tasks), or memory stores (e.g., documents organized in a vector database). Each entity is saved in a database for use across interface interactions. Subsequently, they can define an agent, attaching models, skills, and memory to it. Several agent default templates are provided following AUTOGEN abstractions - a UserProxy agent (has a code execution tool by default), an AssistantAgent (has a generative AI model default), and a GroupChat agent (an abstraction container for defining a list of agents, and how they interact). Finally, workflows can be defined, with existing agents attached to these workflows. The default workflow patterns supported are autonomous chat (agents exchange messages and actions across conversation turns until a termination condition is met) and sequential chat (a sequence of agents defined, each agent processes its input in order and passes on a summary of their output to the next agent). The workflow composition process is further enhanced by supporting a drag-and-drop interaction e.g., skills/models can be dragged to agents and agents into workflows.\n\n# 4.1.2 Testing and Debugging Workflows\n\nWorkflows can be tested in-situ in the build view, or more systematically explored within the playground view. The playground view allows users to create sessions, attach workflows to the session, and run tasks (single shot or multi-turn). Sessions can be shared (to illustrate workflow performance) and multiple sessions can be compared. AUTOGEN STUDIO provides two features to support debugging. First, it provides an observe view where as tasks progress, messages and actions performed by agents are streamed to the interface, and all generated artifacts are displayed (e.g., files such as images, code, documents etc). Second a post-hoc profiler view is provided where a set of metrics are visualized for each task addressed by a workflow.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3783, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "8a747947-138b-4f6a-88cd-757f4f68e659": {"__data__": {"id_": "8a747947-138b-4f6a-88cd-757f4f68e659", "embedding": null, "metadata": {"file_path": "/Users/tylerreed/_ai-projects/llamaindex-beginner-course/pdf/ag-studio.pdf", "file_name": "ag-studio.pdf", "file_type": "application/pdf", "file_size": 3112466, "creation_date": "2024-09-11", "last_modified_date": "2024-09-10"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "69cb95a0-38a7-44d7-a7a3-8fc1fe855b91", "node_type": "4", "metadata": {"file_path": "/Users/tylerreed/_ai-projects/llamaindex-beginner-course/pdf/ag-studio.pdf", "file_name": "ag-studio.pdf", "file_type": "application/pdf", "file_size": 3112466, "creation_date": "2024-09-11", "last_modified_date": "2024-09-10"}, "hash": "0e100f3b6744c4c944e410bf26e08e960663df885e5056aaaede333cfff51190", "class_name": "RelatedNodeInfo"}}, "text": "# Backend API\n\n# A\n\n# Frontend Web UI API\n\n# B\n\nautogenstudio.web.app\n\n# AutoGen Studio\n\n# Book generation\n\n# Recent sessions\n\n# Observe Agents\n\n# Web API\n\ncreate a childrens pdf book with 4 pages, each describing the weather in seattle. Each page should have extensive descriptions with images of the weather. Create the images first, then create the text, then the pdf.\n\n# REST + Socket endpoints for UI\n\n# Build\n\n# Agents have completed the task\n\nObserve this response\n\n# Groupchat manager\n\n|Agent|Tokens|USD|\n|---|---|---|\n|Groupchat manager|12912|0.152|\n|Content|10812|0.122|\n|Userproxy|2912|0.022|\n|Image Generator|901|0.012|\n|Quality Assurance|603|0.009|\n\nThe children's PDF book titled \"Weather in Seattle\" has been successfully created with descriptions and images for each weather condition. The book should now be available as \"Seattle_Weather_Childrens_Book.pdf\" on your system. You can open and view the PDF to ensure that it meets your expectations and contains all the pages with the appropriate images and descriptions. If everything looks good, that completes our task. If you need any further assistance or modifications, please let me know.\n\n# Results (7 files)\n\n# Total messages\n\n|Userproxy|Groupchat manager|Content|Image Generator|Quality Assurance|\n|---|---|---|---|---|\n|0|0|0|0|0|\n\nSeattle_Weather_Childrens_Book.pdf\n\n# Tool call\n\n|Success|Failure|\n|---|---|\n|0|0.5|\n\n# Figure 2\n\nAUTOGEN STUDIO provides a backend api (web, python, cli) and a UI which implements a playground (shown), build and gallery view. In the playground view, users can run tasks in a session based on a workflow. Users can also observe actions taken by agents, reviewing agent messages and metrics based on a profiler module.\n\ntotal number of messages exchanged, costs (generative AI model tokens consumed and dollar costs), how often agents use tools and the status of tool use (success or failure), for each agent.\n\n# 4.1.3 Deploying Workflows\n\nAUTOGEN STUDIO enables users to export workflows as a JSON configuration file. An exported workflow can be seamlessly integrated into any Python application (listing 2), executed as an API endpoint using the AUTOGEN STUDIO command line interface (figure 2a), or wrapped in a Docker container for large-scale deployment on various platforms (Azure, GCP, Amazon, etc.).\n\nfrom autogenstudio import WorkflowManager\nwm = WorkflowManager(\"workflow.json\")\nwm.run(message=\"What is the height of the Eiffel Tower?\")\n# listing 2\n\nWorkflows can be imported in python apps.\n\n# 4.1.4 Template Gallery\n\nThe UI also features a gallery view - a repository of components (skills, models, agents, workflows)\n\nFastAPI: https://fastapi.tiangolo.com/", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2675, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "9eac1dca-6307-4aa9-9a94-27a83e17eb54": {"__data__": {"id_": "9eac1dca-6307-4aa9-9a94-27a83e17eb54", "embedding": null, "metadata": {"file_path": "/Users/tylerreed/_ai-projects/llamaindex-beginner-course/pdf/ag-studio.pdf", "file_name": "ag-studio.pdf", "file_type": "application/pdf", "file_size": 3112466, "creation_date": "2024-09-11", "last_modified_date": "2024-09-10"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "31ff66e8-bfbc-449e-ae56-756830d52186", "node_type": "4", "metadata": {"file_path": "/Users/tylerreed/_ai-projects/llamaindex-beginner-course/pdf/ag-studio.pdf", "file_name": "ag-studio.pdf", "file_type": "application/pdf", "file_size": 3112466, "creation_date": "2024-09-11", "last_modified_date": "2024-09-10"}, "hash": "2713770aa2d51f0f40e1d35b9c86db37470213d2653a7681897f366a72aeb372", "class_name": "RelatedNodeInfo"}}, "text": "# Usage and Evaluation\n\nIn this project, we have adopted an in-situ, iterative evaluation approach. Since its release on GitHub (5 months), the AUTOGEN STUDIO package has been installed over 200K times and has been iteratively improved based on feedback from usage (&gt; 135 GitHub issues). Issues highlighted several user pain points that were subsequently addressed including: (a) challenges in defining, persisting, and reusing components, resolved by implementing a database layer; (b) difficulties in authoring components, resolved by supporting automated tool generation from descriptions and integrating an IDE for editing tools; (c) frustrations caused by components failing during end-to-end tests, addressed by incorporating a test button for components (e.g., models) and workflows in the build view.\n\nFigure 3 displays a plot of all AUTOGEN STUDIO issues. Each point represents an issue, based on an embedding of its text (title + body) using OpenAI\u2019s text-embedding-3-large model. The embeddings were reduced to two dimensions using UMAP, clustered with K-Means (k = 8), and cluster labels generated using GPT-4 (grounded on 10 samples from its centroid). Finally, in Appendix A, we demonstrate how AUTOGEN STUDIO can effectively be used to support an engineer persona in rapidly prototyping, testing, and iteratively debugging a MULTI-AGENT workflow, and deploying it as an API endpoint to address a concrete task (generating books).\n\n# Emerging Design Patterns and Research Directions\n\nIn the following section, we outline some of the high-level emerging patterns which we hope can help inform the design of no-code interfaces for building next-generation multi-agent applications.\n\n# Define-and-Compose Workflows\n\n|AutoGen Studio GitHub Issue Visualization (UMAP)|AutoGen Studio GitHub Issue Visualization (UMAP)|\n|---|\n|Issues with API Keys, Model Configuration, and Local Server Connections|(27)|\n|Issues with AutoGen Studio: Docker access, validation errors, and compatibility|(17)|\n|Issues with AutogenStudio: Skills not updating, Code execution, and Group Chat|(21)|\n|AutoGen Studio 2|Issues with Group Chat Workflow, Agent Creation, and Model Changes|\n|Compatibility, API Issues, and Documentation Updates|(10)|\n|Accessibility and Multimodality in Autogen Studio, UI Improvements, Group Chat Support, and Test Suite|(14)|\n|AutoGen Studio Feature Requests: Workflow Sharing, File Uploads, UI Improvements, and Model Testing|(14)|\n|Database Implementation, Custom Configurations, and Performance Enhancements|(14)|\n\nFigure 3: Plot of GitHub issues (n = 8 clusters) from the AUTOGEN STUDIO repo. User feedback ranged from support with workflow authoring tools (e.g., the ability to configure and test models) to general installation helping users understand what parameters to configure (discovery), and how to configure them. Specifically, we have found that a define-and-compose workflow, where entities are first defined and persisted independently, and then composed ultimately into multi-agent workflows, provides a good developer experience. This includes providing tools to support authoring entities e.g., the ability to define and test models, an IDE for generating/editing tools (code), and a canvas-based visual layout of workflows with drag-and-drop interaction for associating entities in the workflow.\n\n# Debugging and Sensemaking Tools\n\nProvide robust tools to help users debug, interpret, and rationalize the behavior and outputs of multi-agent systems.\n\nAllow users to author workflows by defining components and composing them (via drag-and-drop actions) into multi-agent workflows.\n\nA multi-agent system can have a wide array of parameters to configure. We have found that selecting the right visual presentation of the workflow to help users understand what parameters to configure (discovery), and how to configure them. Multi-agent workflows can be brittle and fail for multiple reasons, ranging from improperly configured models to poor instructions for agents, improper tool configuration for agents or termination conditions. A critical request has been for tools to help users debug and make sense of agent responses.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4162, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "753c0035-3d85-4b5f-a61c-3392b94a6c3c": {"__data__": {"id_": "753c0035-3d85-4b5f-a61c-3392b94a6c3c", "embedding": null, "metadata": {"file_path": "/Users/tylerreed/_ai-projects/llamaindex-beginner-course/pdf/ag-studio.pdf", "file_name": "ag-studio.pdf", "file_type": "application/pdf", "file_size": 3112466, "creation_date": "2024-09-11", "last_modified_date": "2024-09-10"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "506e44fe-9490-4d7e-9f7c-8e1ff1acc51d", "node_type": "4", "metadata": {"file_path": "/Users/tylerreed/_ai-projects/llamaindex-beginner-course/pdf/ag-studio.pdf", "file_name": "ag-studio.pdf", "file_type": "application/pdf", "file_size": 3112466, "creation_date": "2024-09-11", "last_modified_date": "2024-09-10"}, "hash": "cdba90f110bbf08af3043d07cf80d6fd832235797d080b17fadfd5ff7a21f466", "class_name": "RelatedNodeInfo"}}, "text": "# 6.3 Export and Deployment\n\nEnable seamless export and deployment of multi-agent workflows to various platforms and environments.\n\nWhile a no-code tool like AUTOGEN STUDIO enables rapid iteration and demonstration of workflows, the natural progression for most use cases is that developers want to replicate the same outcomes but integrated as parts of their core applications. This stage requires seamless export and deployment of multi-agent workflows to various platforms and environments.\n\n# 6.4 Collaboration and Sharing\n\nFacilitate user collaboration on multi-agent workflow development and allow easy sharing of creations within the community.\n\nCollaboration and sharing are key to accelerating innovation and improving multi-agent systems. By enabling users to collaborate on workflow development, share their creations, and build upon each other\u2019s work, a more dynamic and innovative development environment can be cultivated. Tools and features that support real-time collaboration, version control, and seamless sharing of workflows and components are essential to foster a community-driven approach. Additionally, offering a repository or gallery where users can publish and share their workflows, skills, and agents promotes communal learning and innovation.\n\n# 7 Future Research Directions\n\nWhile we have explored early implementations of the design requirements mentioned above, our efforts in building AUTOGEN STUDIO have also identified two important future research areas and associated research questions.\n\n- Offline Evaluation Tools: This encompasses questions such as how can we measure the performance, reliability, and reusability of agents across tasks? How can we better understand their strengths and limitations? How can we explore alternative scenarios and outcomes? And how can we compare different agent architectures and collaboration protocols?\n- Understanding and quantifying the impact of multi-agent system design decisions: These questions include determining the optimal number and composition of agents for a given problem, the best way to distribute responsibilities and coordinate actions among agents, and the trade-offs between centralized and decentralized control or between homogeneous and heterogeneous agents.\n- Optimizing of multi-agent systems: Research directions here include the dynamic generation of agents based on task requirements and available resources, tuning workflow configurations to achieve the best performance, and adapting agent teams to changing environments and user preferences. Furthermore, how can we leverage human oversight and feedback to improve agent reliability, task performance and safety?\n\n# 8 Conclusion\n\nThis paper introduced AUTOGEN STUDIO, a no-code developer tool for rapidly prototyping, debugging, and evaluating multi-agent workflows. Key features include a drag-and-drop interface for agent workflow composition, interactive debugging capabilities, and a gallery of reusable agent components. Through widespread adoption, we identified emerging design patterns for multi-agent developer tooling - a define and compose approach to authoring workflows, debugging tools to make sense of agent behaviors, tools to enable deployment and collaborative sharing features. AUTOGEN STUDIO lowers the barrier to entry for multi-agent application development, potentially accelerating innovation in the field. Finally, we outline future research directions including developing offline evaluation tools, ablation studies to quantify the impact of MULTI-AGENT systems design decisions and methods for optimizing multi-agent systems.\n\n# 9 Ethics Statement\n\nAUTOGEN STUDIO is designed to provide a no-code environment for rapidly prototyping and testing multi-agent workflows. Our goal is to responsibly advance research and practice in solving problems with multiple agents and to develop tools that contribute to human well-being. Along with AUTOGEN, AUTOGEN STUDIO is committed to implementing features that promote safe and reliable outcomes. For example, AUTOGEN STUDIO offers profiling tools to make sense of agent actions.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4104, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "7f043c9c-995c-4387-bee6-56a800aca5e9": {"__data__": {"id_": "7f043c9c-995c-4387-bee6-56a800aca5e9", "embedding": null, "metadata": {"file_path": "/Users/tylerreed/_ai-projects/llamaindex-beginner-course/pdf/ag-studio.pdf", "file_name": "ag-studio.pdf", "file_type": "application/pdf", "file_size": 3112466, "creation_date": "2024-09-11", "last_modified_date": "2024-09-10"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "a0ff572f-46cd-4d99-896a-1d3c8f72853d", "node_type": "4", "metadata": {"file_path": "/Users/tylerreed/_ai-projects/llamaindex-beginner-course/pdf/ag-studio.pdf", "file_name": "ag-studio.pdf", "file_type": "application/pdf", "file_size": 3112466, "creation_date": "2024-09-11", "last_modified_date": "2024-09-10"}, "hash": "6b3c7d8026e68098dc8fff5de312a611156be7eab518aab800dc4b3a72e86692", "class_name": "RelatedNodeInfo"}}, "text": "# Acknowledgements\n\nWe would like to thank members of the open-source software (OSS) community and the AI Frontiers organization at Microsoft Research for discussions and feedback along the way. Specifically, we would like to thank Piali Choudhury, Ahmed Awadallah, Robin Moeur, Jack Gerrits, Robert Barber, Grace Proebsting, Michel Pahud, Qingyun Wu, Harsha Nori and others for feedback and comments.\n\nBo Qiao, Liqun Li, Xu Zhang, Shilin He, Yu Kang, Chaoyun Zhang, Fangkai Yang, Hang Dong, Jue Zhang, Lu Wang, et al. 2023. Taskweaver: A code-first agent framework. arXiv preprint arXiv:2311.17541.\n\nQingyun Wu, Gagan Bansal, Jieyu Zhang, Yiran Wu, Beibin Li, Erkang Zhu, Li Jiang, Xiaoyun Zhang, Shaokun Zhang, Jiale Liu, Ahmed Hassan Awadallah, Ryen W White, Doug Burger, and Chi Wang. 2023. Autogen: Enabling next-gen llm applications via multi-agent conversation framework. arxiv.\n\nZhiyong Wu, Chengcheng Han, Zichen Ding, Zhenmin Weng, Zhoumianze Liu, Shunyu Yao, Tao Yu, and Lingpeng Kong. 2024. Os-copilot: Towards generalist computer agents with self-improvement. arXiv preprint arXiv:2402.07456.\n\nShunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, and Yuan Cao. 2022. React: Synergizing reasoning and acting in language models. arXiv preprint arXiv:2210.03629.\n\n# References\n\nHarrison Chase. 2022. LangChain. Github.\n\nVictor Dibia. 2023. Lida: A tool for automatic generation of grammar-agnostic visualizations and infographics using large language models. arXiv preprint arXiv:2303.02927.\n\nYilun Du, Shuang Li, Antonio Torralba, Joshua B Tenenbaum, and Igor Mordatch. 2023. Improving factuality and reasoning in language models through multi-agent debate. arXiv preprint arXiv:2305.14325.\n\nGuohao Li, Hasan Hammoud, Hani Itani, Dmitrii Khizbullin, and Bernard Ghanem. 2024. Camel: Communicative agents for \"mind\" exploration of large language model society. Advances in Neural Information Processing Systems, 36.\n\nTian Liang, Zhiwei He, Wenxiang Jiao, Xing Wang, Yan Wang, Rui Wang, Yujiu Yang, Zhaopeng Tu, and Shuming Shi. 2023. Encouraging divergent thinking in large language models through multi-agent debate. arXiv preprint arXiv:2305.19118.\n\nNelson F Liu, Kevin Lin, John Hewitt, Ashwin Paranjape, Michele Bevilacqua, Fabio Petroni, and Percy Liang. 2024. Lost in the middle: How language models use long contexts. Transactions of the Association for Computational Linguistics, 12:157\u2013173.\n\nGr\u00e9goire Mialon, Roberto Dess\u00ec, Maria Lomeli, Christoforos Nalmpantis, Ram Pasunuru, Roberta Raileanu, Baptiste Rozi\u00e8re, Timo Schick, Jane Dwivedi-Yu, Asli Celikyilmaz, et al. 2023. Augmented language models: a survey. arXiv preprint arXiv:2302.07842.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2687, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}, "52f0739a-b56f-4f3d-8384-60969b532f5a": {"__data__": {"id_": "52f0739a-b56f-4f3d-8384-60969b532f5a", "embedding": null, "metadata": {"file_path": "/Users/tylerreed/_ai-projects/llamaindex-beginner-course/pdf/ag-studio.pdf", "file_name": "ag-studio.pdf", "file_type": "application/pdf", "file_size": 3112466, "creation_date": "2024-09-11", "last_modified_date": "2024-09-10"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "146d9731-e382-429b-961d-c4f8837ee599", "node_type": "4", "metadata": {"file_path": "/Users/tylerreed/_ai-projects/llamaindex-beginner-course/pdf/ag-studio.pdf", "file_name": "ag-studio.pdf", "file_type": "application/pdf", "file_size": 3112466, "creation_date": "2024-09-11", "last_modified_date": "2024-09-10"}, "hash": "0ca87cca19e95307a9d8a9ba62df6943872305664e4ea1d891f5d9073b8917e4", "class_name": "RelatedNodeInfo"}}, "text": "# Jack the Software Engineer Persona\n\n# Use Case\n\nJack is a junior software engineer who has recently joined SoftwareCon. As part of his tasks, he is required to create an application that can generate a variety of short books. The initial version should focus on generating children\u2019s books (age 5 - 8 years old) based on a given query (e.g., create a book for kids on how the sun works) with the expectation of being generalized to support other generic tasks. Jack has heard about a MULTI-AGENT approach to building systems that can address a variety of tasks through autonomous collaboration between agents. To explore this approach, he begins by perusing the AUTOGEN STUDIO documentation, installs it, launches the UI, and performs the following steps:\n\n# A.1 Step 1: Define and Compose a Workflow\n\nJack starts with the Build view, where he reviews the default skills that come with AUTOGEN STUDIO. He sees that there are two relevant skills: generate_pdf and generate_images. He verifies that he has the appropriate API keys for the generate_image skill. Next, he creates a GPT3.5 model and adds an API key.\n\nFollowing best practices, Jack knows that the basic agent team with AUTOGEN consists of a UserProxyAgent that can execute code and an AssistantAgent that can solve tasks as well as write code or call available tools/skills. He creates both of these agents; for his AssistantAgent, he ensures that he attaches the GPT4 model he created previously and also attaches both skills. Jack moves on to the workflow tab and creates a new autonomous chat workflow where he specifies the UserProxyAgent as the initiator and his AssistantAgent as the receiver.\n\nOf his AssistantAgent, but still doesn\u2019t get pages with more than 3 sentences across interactive tests. He recalls that using more agents can help separate focus and improve task performance. He then switches to creating 4 agents: a UserProxy, a ContentAssistant with detailed instructions on generating the content for each page, a QualityAssuranceAssistant to verify the pages meet parameters, and an ImageGeneratorAssistant focused on generating images for the book. He then creates a GroupChat agent and adds his list of agents to it. Next, he creates a new workflow where the receiver is the GroupChat agent and tests the application across a few tries. Jack is satisfied with the results as full-page stories are now generated correctly. In addition, Jack is concerned about costs but can easily use the observe message button to explore duration, tokens used by agents, tool/skill use and LLM dollar costs for each task run.\n\n# A.2 Step 2: Test and Iterate\n\nWithin the workflow tab, Jack tests the workflow immediately and quickly observes a few issues. Using the profiler tool and visualization of messages exchanged by the agents, he notices that there seem to be quality issues with the content of the book - namely, the AssistantAgent seems to generate very short messages and hence the book pages contain only 2 sentences per page whereas the requirements state that the kids are slightly older and can read much longer text.\n\nTo remedy these issues, Jack takes two actions. First, he attempts to extend the base instructions.\n\n# A.3 Step 3: Export and Share\n\nAt this point, Jack has two final tasks: he wants to share his work with colleagues for feedback and then provide an API they can prototype with. AUTOGEN STUDIO makes sharing easy; First, Jack can simply export and share a link to successful sessions. Second, he can also download his workflow and share it with colleagues, saving it in a version control system like Git. Third, he can spin up an API endpoint where the agents can respond to task requests using CLI commands \u2018autogenstudio serve \u2013port 8000\u2018. He can also spin up a docker container using the AUTOGEN STUDIO serve command and scale it on any platform of his choice (Azure, AWS, GCP, Hugging Face).", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3899, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n", "class_name": "TextNode"}, "__type__": "1"}}, "docstore/ref_doc_info": {"5df792c2-0d94-4819-9563-5fd313a519cd": {"node_ids": ["e00004c9-657e-454c-94a7-638ec8065954"], "metadata": {"file_path": "/Users/tylerreed/_ai-projects/llamaindex-beginner-course/pdf/ag-studio.pdf", "file_name": "ag-studio.pdf", "file_type": "application/pdf", "file_size": 3112466, "creation_date": "2024-09-11", "last_modified_date": "2024-09-10"}}, "67d354a0-8e58-4a6a-b40e-4880c326aa6d": {"node_ids": ["7af7addd-7c5e-4e45-8f82-b27521921072"], "metadata": {"file_path": "/Users/tylerreed/_ai-projects/llamaindex-beginner-course/pdf/ag-studio.pdf", "file_name": "ag-studio.pdf", "file_type": "application/pdf", "file_size": 3112466, "creation_date": "2024-09-11", "last_modified_date": "2024-09-10"}}, "ff707a45-567f-44ce-89b3-f744c1b9d8bd": {"node_ids": ["97cf30dd-f3d5-4eea-8c7c-2966a304fad4"], "metadata": {"file_path": "/Users/tylerreed/_ai-projects/llamaindex-beginner-course/pdf/ag-studio.pdf", "file_name": "ag-studio.pdf", "file_type": "application/pdf", "file_size": 3112466, "creation_date": "2024-09-11", "last_modified_date": "2024-09-10"}}, "69cb95a0-38a7-44d7-a7a3-8fc1fe855b91": {"node_ids": ["8a747947-138b-4f6a-88cd-757f4f68e659"], "metadata": {"file_path": "/Users/tylerreed/_ai-projects/llamaindex-beginner-course/pdf/ag-studio.pdf", "file_name": "ag-studio.pdf", "file_type": "application/pdf", "file_size": 3112466, "creation_date": "2024-09-11", "last_modified_date": "2024-09-10"}}, "31ff66e8-bfbc-449e-ae56-756830d52186": {"node_ids": ["9eac1dca-6307-4aa9-9a94-27a83e17eb54"], "metadata": {"file_path": "/Users/tylerreed/_ai-projects/llamaindex-beginner-course/pdf/ag-studio.pdf", "file_name": "ag-studio.pdf", "file_type": "application/pdf", "file_size": 3112466, "creation_date": "2024-09-11", "last_modified_date": "2024-09-10"}}, "506e44fe-9490-4d7e-9f7c-8e1ff1acc51d": {"node_ids": ["753c0035-3d85-4b5f-a61c-3392b94a6c3c"], "metadata": {"file_path": "/Users/tylerreed/_ai-projects/llamaindex-beginner-course/pdf/ag-studio.pdf", "file_name": "ag-studio.pdf", "file_type": "application/pdf", "file_size": 3112466, "creation_date": "2024-09-11", "last_modified_date": "2024-09-10"}}, "a0ff572f-46cd-4d99-896a-1d3c8f72853d": {"node_ids": ["7f043c9c-995c-4387-bee6-56a800aca5e9"], "metadata": {"file_path": "/Users/tylerreed/_ai-projects/llamaindex-beginner-course/pdf/ag-studio.pdf", "file_name": "ag-studio.pdf", "file_type": "application/pdf", "file_size": 3112466, "creation_date": "2024-09-11", "last_modified_date": "2024-09-10"}}, "146d9731-e382-429b-961d-c4f8837ee599": {"node_ids": ["52f0739a-b56f-4f3d-8384-60969b532f5a"], "metadata": {"file_path": "/Users/tylerreed/_ai-projects/llamaindex-beginner-course/pdf/ag-studio.pdf", "file_name": "ag-studio.pdf", "file_type": "application/pdf", "file_size": 3112466, "creation_date": "2024-09-11", "last_modified_date": "2024-09-10"}}}}